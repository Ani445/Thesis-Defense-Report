\chapter{Introduction}
\label{chap:introduction}

\section{Semantic Segmentation}
\label{sec:semantic_segmentation}
Semantic segmentation is a fundamental task in computer vision that involves partitioning an image into semantically meaningful regions. Each pixel in the image is assigned a label corresponding to the object or region it belongs to. This task is crucial for applications such as autonomous driving, medical image analysis, and scene understanding.

The goal of semantic segmentation is to achieve pixel-level understanding of an image, which is more detailed than traditional image classification or object detection. Unlike these tasks, semantic segmentation requires not only identifying the presence of objects but also delineating their precise boundaries.


\subsection{Fully Supervised Semantic Segmentation}
\label{subsec:fully_supervised}
Fully supervised semantic segmentation methods rely on large amounts of labeled data, where each pixel in the training images is annotated with its corresponding class label. These methods typically use deep learning architectures, such as convolutional neural networks (CNNs), to learn complex features and patterns from the labeled data. The performance of these models is heavily dependent on the quality and quantity of the annotated data.

\subsection{Weakly Supervised Semantic Segmentation}
\label{subsec:weakly_supervised}
Weakly supervised semantic segmentation aims to reduce the reliance on extensive pixel-level annotations by utilizing weaker forms of supervision, such as image-level labels, bounding boxes, or scribbles. This approach allows for the training of segmentation models with limited labeled data while leveraging large amounts of unlabeled data. Weakly supervised methods have gained popularity due to their ability to achieve competitive performance with significantly less annotation effort.

\section{Motivation}
\label{sec:motivation}

Semantic segmentation has established itself as a fundamental task in computer vision, with broad applications in areas such as autonomous driving, medical imaging, and robotics. In these domains, a precise pixel-level understanding of the environment is not merely desirable but often critical: for example, safe navigation of self-driving vehicles relies on reliable scene parsing, and accurate delineation of anatomical structures can directly impact medical diagnosis and treatment.

Despite its importance, conventional semantic segmentation has been heavily reliant on fully supervised learning. This paradigm demands large-scale datasets with dense pixel-level annotations, which are costly and labor-intensive to produce. Annotating high-resolution images can take hours per image, and the process remains prone to human error. Beyond annotation effort, fully supervised methods face additional hurdles: (i) class imbalance in real-world datasets often biases models toward dominant categories, (ii) complex scenes with occlusion, lighting variation, and fine structural detail challenge the robustness of predictions, and (iii) models trained on specific datasets frequently fail to generalize across domains due to dataset-specific biases.

These challenges naturally motivate the exploration of weakly supervised semantic segmentation (WSSS). By replacing dense annotations with weaker forms of supervision—such as image-level labels, bounding boxes, or scribbles—WSSS reduces annotation cost while still enabling model training. The key idea is to leverage weak supervision to generate class activation maps (CAMs) and corresponding pseudo-labels, which can then guide the segmentation process. Although CAMs are often coarse or noisy, refinement strategies allow them to approximate dense ground truth, making WSSS a practical compromise between annotation effort and segmentation performance.

The motivation for this research is thus twofold: first, to address the scalability and practicality issues of fully supervised methods, and second, to improve the quality and reliability of WSSS pipelines. By advancing WSSS, we aim to narrow the performance gap with fully supervised segmentation while ensuring that solutions remain feasible for deployment in diverse and data-constrained real-world scenarios.



\section{Problem Statement}
\label{sec:problem_statement}

Weakly Supervised Semantic Segmentation (WSSS) presents a compelling alternative to fully supervised methods by significantly reducing the dependence on costly pixel-level annotations. However, current WSSS techniques rely on Class Activation Maps (CAMs) \cite{cam} generated from image-level labels to identify object regions. While this approach has shown promise, it often falls short in terms of spatial precision and completeness, leading to suboptimal segmentation results.

In the context of WSSS, the challenge lies in effectively leveraging the image-level labels to produce accurate and detailed segmentation maps. The dependence on CAMs, which are typically generated from global features, can result in sparse and coarse activation maps that fail to capture the fine details of object boundaries. This limitation is particularly pronounced when dealing with complex scenes or occlusions, where precise localization is crucial.

Additionally, the refinement techniques applied to these CAMs often fail to fully leverage the rich affinity information inherent in modern transformer architectures. Consequently, the resulting pseudo-labels lack the spatial precision required for high-quality segmentation, ultimately impacting the overall performance. This highlights the need for more robust backbone architectures capable of effectively capturing both local and global features, as well as advanced CAM refinement strategies to narrow the performance gap between weakly and fully supervised segmentation methods.

So, keeping in mind the above challenges, we aim to develop a weakly supervised semantic segmentation model that can effectively leverage image-level labels to produce accurate and detailed segmentation maps. Our approach will focus on enhancing the spatial precision and completeness of the generated CAMs.

\section{Challenges of Semantic Segmentation}
\label{sec:challenges_of_semantic_segmentation}
Semantic segmentation faces several challenges that hinder its widespread adoption and effectiveness:

\section{Challenges of Weakly Supervised Semantic Segmentation}
\label{sec:challenges_of_wsss}

While weakly supervised semantic segmentation (WSSS) reduces the annotation burden compared to fully supervised methods, it introduces its own set of challenges:

\begin{itemize}
    \item \textbf{Incomplete Object Localization:} Class activation maps (CAMs) derived from image-level labels typically highlight only the most discriminative regions, leaving large portions of the object unlabeled.
    \item \textbf{Noisy Pseudo-labels:} The process of refining CAMs into pixel-level labels often introduces noise and errors, which can propagate during training and degrade performance.
    \item \textbf{Boundary Precision:} Weak supervision lacks explicit boundary cues, making it difficult to segment fine object details and separate adjacent instances accurately.
    \item \textbf{Background Confusion:} Without strong pixel-level supervision, models often misclassify diverse background regions as foreground, or vice versa.
    \item \textbf{Multi-class Co-occurrence:} In scenes containing multiple objects, weak labels struggle to capture clear distinctions, leading to overlapping or missing class activations.
    \item \textbf{Class Imbalance:} Underrepresented classes may not produce strong activations in CAMs, resulting in poor segmentation for rare categories.
    \item \textbf{Dependence on External Cues:} Many WSSS methods rely on saliency maps or additional priors to improve CAMs, but these external cues may be dataset-specific and limit generalization.
\end{itemize}

Addressing these challenges is crucial for advancing WSSS methods toward practical applications where annotation resources are limited.


\section{Contribution}
\label{sec:contribution}

In this work, we make the following key contributions:

\begin{itemize}
    \item We explore the use of the UniCL framework \cite{vl_unicl} with a Swin Transformer backbone \cite{transformer_swin} to enhance CAM generation, leveraging Swin's ability to capture both local fine details and global context through its hierarchical structure.
    \item We adapt the affinity-based CAM refinement technique from WeCLIP \cite{wsss_frozen_clip} to the Swin Transformer backbone by computing pixel affinities from Swin's hierarchical features, allowing the refinement to propagate class activations effectively despite the absence of a global attention map.
    \item We integrate a Pixel-Adaptive Refinement Module (PAR) \cite{wsss_afa_affinity_from_attention} that incorporates both color and spatial information, further refining the pseudo-labels and enhancing boundary accuracy.
    \item We integrate the refined CAMs and Pixel-Adaptive Refinement into the standard WSSS training pipeline, training the model to leverage these improved pseudo-labels for better segmentation performance.

\end{itemize}

\section{Organization}
\label{sec:organization}

The remainder of this thesis report is organized as follows:

\begin{itemize}
    \item \textbf{Chapter \ref{chap:related-works}: Related Works} provides a comprehensive review of existing literature on semantic segmentation. It discusses fully supervised and weakly supervised methods, key architectures like U-Net, DeepLab, and Vision Transformers, and identifies gaps in current research.

    \item \textbf{Chapter \ref{chap:methodology}: Proposed Methodology} details the proposed approach, including the use of the UniCL framework with a Swin Transformer backbone for CAM generation. It also describes the affinity-based CAM refinement technique and the Pixel-Adaptive Refinement Module (PAR) for pseudo-label generation and segmentation refinement.

    \item \textbf{Chapter \ref{chap:citations}: Citations} provides guidance on managing references using \texttt{biblatex}, with examples of citing articles, books, and multi-citations.

    \item \textbf{Appendices} include supplementary materials such as additional figures, tables, and extended discussions that support the main content of the thesis.
\end{itemize}

This structure ensures a logical flow, starting from the foundational concepts and related works, progressing through the proposed methodology, and concluding with the results, discussions, and supplementary materials.

