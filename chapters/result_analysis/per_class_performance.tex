\subsection{Per-Class Performance Analysis}
\label{subsec:per_class_performance_analysis}

To gain a deeper understanding of our model’s behavior, we analyzed the per-class Intersection over Union (IoU) scores on both the PASCAL VOC 2012 validation and test sets. This joint analysis highlights how the model performs across different object categories, providing insights beyond the overall metrics.

\subsubsection{High-Performing Classes}

On the \textbf{validation set}, large and distinctive categories achieved strong results such as \textbf{background} (78.2\%), \textbf{bus} (67.8\%), \textbf{sheep} (62.0\%), \textbf{horse} (60.9\%), and \textbf{cat} (65.2\%).  
On the \textbf{test set}, similar trends were observed with strong performance for \textbf{cow} (72.5\%), \textbf{bus} (67.8\%), \textbf{sheep} (65.5\%), \textbf{horse} (64.9\%), and \textbf{background} (77.6\%).

\subsubsection{Low-Performing Classes}

On the \textbf{validation set}, small or less frequent categories such as \textbf{person} (16.9\%), \textbf{chair} (26.1\%), and \textbf{potted plant} (28.7\%) exhibited the lowest IoUs.  
On the \textbf{test set}, the weakest categories remained consistent, with \textbf{person} (16.7\%), \textbf{chair} (26.1\%), and \textbf{bicycle} (23.3\%) showing poor performance.


\begin{table}[th]
\centering
\caption{Per-Class IoU Performance on PASCAL VOC (Validation vs Test Sets)}
\begin{tabular}{r l c c}
\hline
\textbf{Index} & \textbf{Class} & \textbf{Val IoU} & \textbf{Test IoU} \\ \hline
0  & background   & 0.782 & 0.776 \\
1  & aeroplane    & 0.566 & 0.625 \\
2  & bicycle      & 0.330 & 0.233 \\
3  & bird         & 0.610 & 0.623 \\
4  & boat         & 0.431 & 0.504 \\
5  & bottle       & 0.382 & 0.333 \\
6  & bus          & 0.678 & 0.678 \\
7  & car          & 0.495 & 0.436 \\
8  & cat          & 0.652 & 0.637 \\
9  & chair        & 0.261 & 0.261 \\
10 & cow          & 0.595 & 0.725 \\
11 & diningtable  & 0.420 & 0.346 \\
12 & dog          & 0.660 & 0.648 \\
13 & horse        & 0.609 & 0.649 \\
14 & motorbike    & 0.576 & 0.548 \\
15 & person       & \textcolor{red}{0.169} & \textcolor{red}{0.167} \\
16 & pottedplant  & 0.287 & 0.333 \\
17 & sheep        & 0.620 & 0.655 \\
18 & sofa         & 0.465 & 0.534 \\
19 & train        & 0.558 & 0.600 \\
20 & tvmonitor    & 0.419 & 0.355 \\ \hline
\end{tabular}
\label{tab:per_class_iou_comparison}
\end{table}

\begin{table}[ht]
\centering
\caption{Overall Performance Metrics on PASCAL VOC}
\begin{tabular}{l c c}
\hline
\textbf{Metric} & \textbf{Validation} & \textbf{Test} \\ \hline
Pixel Accuracy (pAcc) & 0.801 & 0.796 \\
Mean Accuracy (mAcc)  & 0.700 & 0.714 \\
Mean IoU (mIoU)       & 0.503 & 0.508 \\ \hline
\end{tabular}
\label{tab:summarized_results}
\end{table}


\subsubsection{Observations}

Across both validation and test sets, the model demonstrates strong performance on large and visually distinctive classes such as animals and vehicles, while it consistently underperforms on humans, furniture, and small objects. Notably, some categories show improved generalization on the test set compared to validation — for example, \textbf{boat} improves from 43.1\% (val) to 50.4\% (test), and \textbf{sofa} improves from 46.5\% (val) to 53.3\% (test). 

A major factor behind the weak performance on certain categories is the composition of the datasets used for UniCL pretraining. UniCL was pretrained on \textbf{ImageNet-21K (IN-21K)} and \textbf{YFCC-14M}, which together cover a very large number of classes (21K+ in IN-21K) and a broad variety of images, but they do not include or sparsely represent some categories present in PASCAL VOC, such as \textbf{person}, \textbf{chair}, and \textbf{potted plant}. Consequently, the model has limited exposure to these classes during pretraining and struggles to learn transferable representations for them, leading to very low IoU scores — for example, 16.9\% (val) and 16.7\% (test) for \textbf{person}. 

This severe underperformance on frequently occurring but underrepresented categories substantially lowers the overall mean IoU, despite strong performance on large and distinctive objects. These findings highlight the importance of incorporating multi-scale features, class-specific augmentation, and addressing pretraining dataset biases to improve performance on underrepresented and small-object categories.



