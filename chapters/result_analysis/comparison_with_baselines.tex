\begin{table}[!t]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \setlength{\tabcolsep}{6pt}
    \begin{tabular}{l c c c c}
        \hline
        \textbf{Approach}                                                               & \textbf{Backbone}   & \textbf{Sup.} & \textbf{val}           & \textbf{test}          \\
        \hline
        \multicolumn{5}{c}{\textit{multi-stage weakly supervised approaches}}                                                    \\
        RCA$_{\text{CVPR'22}}$~\cite{wsss_RCA}             & ResNet101  & I+S  & 72.2          & 72.8          \\
        L2G$_{\text{CVPR'22}}$~\cite{wsss_L2G}             & ResNet101  & I+S  & 72.1          & 71.7          \\
        Mat-label$_{\text{ICCV'23}}$~\cite{wsss_MatLabel}  & ResNet101  & I+S  & 73.3          & \textbf{74.0} \\
        S-BCE$_{\text{ECCV'22}}$~\cite{wsss_s_bce}         & ResNet38   & I+S  & 68.1          & 70.4          \\
        RIB$_{\text{NeurIPS'21}}$~\cite{wsss_rib}          & ResNet38   & I    & 68.3          & 68.6          \\
        W-OoD$_{\text{CVPR'22}}$~\cite{wsss_ood}      & ResNet101  & I    & 69.8          & 69.9          \\
        ESOL$_{\text{NeurIPS'22}}$~\cite{wsss_esol}   & ResNet101  & I    & 69.9          & 69.3          \\
        VML$_{\text{IJCV'22}}$~\cite{wsss_vml}        & ResNet101  & I    & 70.6          & 70.7          \\
        AETF$_{\text{ECCV'22}}$~\cite{wsss_aetf}      & ResNet38   & I    & 70.9          & 71.7          \\
        MCTformer$_{\text{CVPR'22}}$~\cite{wsss_MCTformer} & ViT+Res38  & I    & 70.4          & 70.0          \\
        CDL$_{\text{IJCV'23}}$~\cite{wsss_cdl}        & ResNet101  & I    & 72.4          & 72.2          \\
        ACR$_{\text{CVPR'23}}$~\cite{wsss_acr}        & ViT        & I    & 72.4          & 72.4          \\
        BECO$_{\text{CVPR'23}}$~\cite{wsss_beco}      & MIT-B2     & I    & 73.7          & 73.5          \\
        FPR$_{\text{ICCV'23}}$~\cite{wsss_fpr}        & ResNet101  & I    & 70.0          & 70.6          \\
        USAGE$_{\text{ICCV'23}}$~\cite{wsss_usage}    & ResNet38   & I    & 71.9          & 72.8          \\
        CLIMS$_{\text{CVPR'22}}$~\cite{wsss_clims}    & ViT+Res101 & I+L  & 70.4          & 70.0          \\
        CLIP-ES$_{\text{CVPR'23}}$~\cite{wsss_clip_es}                       & ViT+Res101 & I+L  & \textbf{73.8} & 73.9          \\
        \hline
        \multicolumn{5}{c}{\textit{single-stage weakly supervised approaches}}                                                   \\
        1Stage$_{\text{CVPR'20}}$~\cite{wsss_single_stage}                   & ResNet38   & I    & 62.7          & 64.3          \\
        RRM$_{\text{AAAI'20}}$~\cite{wsss_reliability_does_matter}           & ResNet38   & I    & 62.6          & 62.9          \\
        AA\&AR$_{\text{ACMMM'21}}$~\cite{wsss_aaar}                                 & ResNet38   & I    & 63.9          & 64.8          \\
        SLRNet$_{\text{IJCV'22}}$~\cite{wsss_slr_net}                                  & ResNet38   & I    & 67.2          & 67.6          \\
        AFA$_{\text{CVPR'22}}$~\cite{wsss_afa_affinity_from_attention}                                     & MIT-B1     & I    & 66.0          & 66.3          \\
        TSCD$_{\text{AAAI'23}}$~\cite{wsss_tscd}                                    & MIT-B1     & I    & 67.0          & 67.5          \\
        ToCo$_{\text{CVPR'23}}$~\cite{wsss_toco_token_contrast}                                    & ViT        & I    & 71.1          & 72.2          \\
        WeCLIP (w/o CRF)                                                & ViT        & I+L  & 74.9          & 75.2          \\
        WeCLIP (w/ CRF)                                                 & ViT        & I+L  & \textbf{76.4} & \textbf{77.2} \\
        \hline
        \textbf{Ours - UniCL-AffSeg(w/oCRF)} & Swin-B & I+L & 50.0 & 50.0 \\
        \hline
    \end{tabular}
    \caption{
    Comparison of multi-stage and single-stage weakly supervised semantic segmentation methods on the PASCAL VOC 2012 validation and test sets (mIoU, \%). 
    Here, \textbf{I} denotes image-level supervision, \textbf{L} denotes language supervision, and \textbf{S} denotes saliency supervision. 
    Our method (\textbf{UniCL-AffSeg}) employs Swin-B as the backbone or image encoder. Without description, all have used Dense CRF during inference.
    }
    \label{tab:quantitative_results}
\end{table}

\subsection{Comparison with Exisiting Methods}
\label{subsec:comparison_with_baseline_methods}
Table~\ref{tab:quantitative_results} compares our proposed approach (UniCL) with both multi-stage and single-stage weakly supervised semantic segmentation (WSSS) methods. While state-of-the-art single-stage approaches such as WeCLIP achieve strong performance (76.4\%/77.2\% with CRF post-processing), our current UniCL-AffSeg implementation yields relatively modest results (50.0\% on both validation and test sets).  

It is important to note that UniCL-AffSeg follows a pipeline similar to WeCLIP, but with a critical distinction in how localization cues are obtained. Whereas WeCLIP relies on attention maps derived from a ViT backbone, UniCL-AffSeg leverages affinity maps computed from the Swin Transformer image encoder in combination with a ViT text encoder. Due to the window-based self-attention mechanism in Swin, the resulting feature representations tend to be more \textit{local} and less globally coherent than ViT attention maps. Consequently, the affinity maps fail to capture holistic object-level relationships, leading to weaker class activation maps (CAMs) at initialization. These initial CAMs often exhibit fragmented activations, particularly for large or complex objects, which limits the effectiveness of subsequent refinement stages.  

Furthermore, the feature maps extracted from the Swin image encoder, while rich in local details, lack the global semantic consistency necessary for reliable region affinity learning. This discrepancy explains why UniCL-AffSeg underperforms compared to WeCLIP, despite both methods operating within a broadly similar weakly supervised framework.  

% In summary, although UniCL-AffSeg adopts the same overarching design philosophy as WeCLIP, its reliance on Swin-based affinity maps rather than ViT-based attention maps hinders its ability to generate high-quality initial CAMs and to propagate semantic information effectively. These observations suggest that improving the global reasoning ability of the Swin image encoder, or integrating hybrid mechanisms that combine local affinity with global attention, may be essential for closing the performance gap with current state-of-the-art methods.





\newpage

\begin{figure}[H]
  \centering
  \setlength{\tabcolsep}{2pt} % adjust spacing
  \renewcommand{\arraystretch}{0.3}

  % Wrap the table in a colored box (requires \usepackage{tcolorbox})
  \begin{tcolorbox}[colframe=black!60, colback=white, boxrule=0.8pt, arc=2pt, left=2pt, right=2pt, top=2pt, bottom=2pt]
    \centering
    % CAMs with class labels on the left
    \begin{tabular}{m{2.5cm} c c c} % first column = label

    % Column headers
    & (a) Input & (b) WeCLIP & (c) Ours
    \\
    [1mm]

    {\textbf{Cat}}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2007_003778}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/weclip/2007_003778_7}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/ours/2007_003778_7}
    \\
    \textbf{Bicycle}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2011_000453}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/weclip/2011_000453_1}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/ours/2011_000453_1}
    \\
    \textbf{Bird}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2011_001902}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/weclip/2011_001902_2}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/ours/2011_001902_2}
    \\
    \textbf{Boat}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2010_003599}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/weclip/2010_003599_3}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/ours/2010_003599_3}
    \\
    \textbf{Pottedplant}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2011_000145}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/weclip/2011_000145_15}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/ours/2011_000145_15}
    \\
    \textbf{Car}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2010_005119}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/weclip/2010_005119_6}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/ours/2010_005119_6}
    \\
    \textbf{Bus}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2010_000148}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/weclip/2010_000148_5}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/ours/2010_000148_5}
    \\
    \textbf{Person}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2007_005702}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/weclip/2007_005702_14}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/val_cams/ours/2007_005702_14}
  \end{tabular}

  \end{tcolorbox}

  \caption{Qualitative comparison of CAMs between WeCLIP and our UniCL-AffSeg on PASCAL VOC 2012 \textit{val} set.}
  \label{fig:qualitative_comparison_cam_val}
\end{figure}



\begin{figure}[H]
  \centering
  \setlength{\tabcolsep}{2pt} % adjust spacing
  \renewcommand{\arraystretch}{0.3}

  % Wrap the table in a colored box (requires \usepackage{tcolorbox})
  \begin{tcolorbox}[colframe=black!60, colback=white, boxrule=0.8pt, arc=2pt, left=2pt, right=2pt, top=2pt, bottom=2pt]
    \centering
    % CAMs with class labels on the left
    \begin{tabular}{m{2.5cm} c c c} % first column = label

    % Column headers
    & (a) Input & (b) WeCLIP & (c) Ours
    \\
    [1mm]

    {\textbf{Motorbike}}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2007_002260}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/weclip/2007_002260_13}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/ours/2007_002260_13}
    \\
    \textbf{Aeroplane}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2007_000033}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/weclip/2007_000033_0}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/ours/2007_000033_0}
    \\
    \textbf{Train}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2007_000123}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/weclip/2007_000123_18}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/ours/2007_000123_18}
    \\
    \textbf{Dog}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2007_003194}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/weclip/2007_003194_11}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/ours/2007_003194_11}
    \\
    \textbf{Car}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2007_006277}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/weclip/2007_006277_6}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/ours/2007_006277_6}
    \\
    \textbf{Bird}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2007_001289}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/weclip/2007_001289_2}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/ours/2007_001289_2}
    \\
    \textbf{Person}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2007_000783}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/weclip/2007_000783_14}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/ours/2007_000783_14}
    \\
    \textbf{Chair}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/originals/2007_005844}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/weclip/2007_005844_8}
    & \includegraphics[width=0.18\textwidth,height=0.18\textwidth]{figures/test_cams/ours/2007_005844_8}
    \\
  \end{tabular}

  \end{tcolorbox}

  \caption{Qualitative comparison of CAMs between WeCLIP and our UniCL-AffSeg on PASCAL VOC 2012 \textit{test} set.}
  \label{fig:qualitative_comparison_cam_test}
\end{figure}