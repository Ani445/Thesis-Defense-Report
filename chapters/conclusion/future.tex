\section*{Future Work}
\label{sec:future}


So far, we have explored various models, architectures, and methods for refining CAMs, pseudo-labels, and segmentation maps; however, there remain several promising directions for future research and improvement. Building on recent advances in weakly supervised semantic segmentation, CLIP, and UniCL, these directions aim to enhance both model performance and generalization, while addressing limitations observed in current approaches.

Future work can focus on experimenting with diverse backbones and decoder architectures, such as ViT, ResNet variants, or Mix Transformer, to improve CAM and segmentation quality. Advanced feature aggregation techniques, including transformer-based fusion modules and multi-scale feature alignment, may enhance the integration of intermediate feature and attention maps. Refining CAMs and pseudo-labels using graph-based, CRF-based, affinity-based, uncertainty-aware, or region-based strategies can further improve semantic coherence. Additionally, exploring alternative segmentation heads, novel objective functions like region-based or contrastive losses, and prompt engineering for multi-modal models like CLIP or UniCL can strengthen learning and alignment, especially for rare or ambiguous classes. Leveraging self-supervised or semi-supervised pretraining and combining local-global reasoning through hybrid architectures, such as Swin Transformer and ViT, may further boost feature representation and semantic propagation. Finally, evaluating models for cross-dataset generalization can improve adaptability across datasets with different distributions or label sets.

Collectively, these future directions provide a comprehensive roadmap for advancing weakly supervised semantic segmentation and multi-modal learning. They highlight opportunities to improve architectural design, feature aggregation, refinement strategies, and model generalization, paving the way for more accurate, robust, and scalable segmentation systems.